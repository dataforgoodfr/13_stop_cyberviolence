---
modified: '2025-07-21'
title: StopCyberviolence documentation
---

# Agentic framework and structure

:::{#fig-agentlayout}
![The structure of the `service1` agent.](./img/graph.png)
:::

**Implementation details**

At the current state, the main agent logic is implemented as a monolith in the main .py file : `chatbot/agents/service1/service1.py`

The agent is implemented using `langgraph` and calls the `gemini` API (OpenAI syntax) using the convenience wrappers import from `langchain`.

All data models for :

- the current graph state
- schemas used for requesting structured output

are also defined in `service1.py` as `TypedDict`.

## Node descriptions

- `agent1`

    Router node that determines the next action based on the message history

- `collect_context`

    This node is only active in the beginning of the conversation and the graph flow is forced through this node until all required context questions have been asked.

- `ask_for_context`

    The conversation is routed through this node when `agent1` determines that the context of the situation still needs clarification.

- `give_advice`

    Node responsible for redacting an advice message, is encouraged to invoke `research_strategies` to enrich answers with ingested documents (see below)

- `research_strategies`

    Is invoked by `give_advice`, documents provided by the School of Social networks and StopCyberviolence are provided using prompt stuffing. Exchanges between `give_advice` and `research_strategies` are handled via the graph state but kept apart from the general message flow in order to save tokens and preserve context.

- `classify_message`

    This node is an artifact from early development. Its purpose was to provide a tool for the agent to classify the message of interest as cyberviolence using a classical NLP approach. 
    Not implemented (yet), might be removed in the future.

- `user_feedback`

    Also an artifact from early development for debuggin purposes, to be removed in the future

## Routings



# Local development

## Environment preparation {#sec-envprep}

The project uses a combination of `mamba (conda)` (non-python dependencies) and `uv` (python dependecies) for environment management.

*Backend environment*

```bash
mamba create -n stopcyber_backend -c conda-forge uv 
uv pip install -r ./chatbot/chatbot_reqs.txt
```

*Frontend environment*

```bash
mamba create -n stopcyber_frontend -c conda-forge nodejs pnpm
```

## Backend development {#sec-locbackdev}

For environment creation see @sec-envprep.

**clone app repo**

```bash
git clone https://github.com/dataforgoodfr/13_stop_cyberviolence
```

* AI Agent
* Datalayer

## Frontend development

### Chainlit React Layer

#### Preparation

If the frontend environment is ready, proceed as detailed below, else see @sec-envprep. 

**clone `chainlit` fork**

```bash
git clone --single-branch --branch dev_monster https://github.com/kantundpeterpan/chainlit.git
```

In order to launch a REACT development server and connecting the chatbot app, the backend environment needs to be created and the chatbot app repo needs to be cloned see @sec-envprep and @sec-locbackdev.  

#### Frontend development setup

1. Launch React dev server

```bash
# from the chainlit repo
cd frontend/
npm run dev

### Output:
VITE v5.4.14  ready in 1481 ms

  ➜  Local:   http://localhost:5173/
  ➜  Network: use --host to expose
  ➜  press h + enter to show help
###
```

2. Launch `chainlit` app

```bash
# from app repo ./chatbot
SERVICE1_PROVIDER=gemini chainlit run -h chainlit_app.py
```

Make sure all necessary env vars are set correctly (see below).

3. (Optional if remote) Forward ports

```bash
ssh user@ip_to_remote -NL 5173:localhost:5173
ssh user@ip_to_remote -NL 8000:localhost:8000
```

4. Develop


### Chainlit Python layer

- `config.toml`
- `public`

# Deployment

Last updated: 2025-06-05

## Docker files 

- [./python_uv_node.Dockerfile](./python_uv_node.Dockerfile)

    Customisation of the UI required forking [`chainlit`](https://github.com/kantundpeterpan/chainlit), this container contains the base environment for building directly from the fork repo (`(p)npm`)

- [./chainlit_dev.Dockerfile](./chainlit_dev.Dockerfile)

    Based on the `python_uv_node` image,  for an environment container based on [../chatbot_reqs.txt](../chatbot_reqs.txt), requirements possibly a bit bloated

- [./chatbot_deploy.Dockerfile](./chatbot_deploy.Dockerfile)

    App container image, based on the environment image

## Local deployment

- from within the cloned repo, the app can be started using [../docker_call](../docker_call), if the necessary environment variables are set correctly.

## CI/CD

### Frontend changes pushed to production

The frontend repo is configured to trigger a rebuild and push to `dockerhub` of the custom `chainlit` environment container.

*Important files, repos*

- github workflow emitting a `repository_dispatch` on chainlit fork:
    - production branch `monstermessenger`

- github workflow processing the `repository_dispatch` on chatbot repo:
    - [x] build and push the environment container
    - [ ] trigger Google Cloud Build/Run to rebuild with the new env-container

### Backend / Chainlit python layer changes pushed to production

Changes pushed to `main` of the chatbot repo trigger Google Cloud Build/Run (see below)

### Google Cloud Build / Run

- Google Cloud Build is configured in the github applications of the repo and builds [..//chatbot_deploy.Dockerfile](./chatbot_deploy.Dockerfile)
on each push to `main`

- Currently a single version is running, using the `generativelanguage` API of Google Cloud
- Model: `gemini-flash-2.0`
- The following secrets are set as environment variables in the Google Cloud Run configuration:

    - LANGFUSE_{AZURE/GEMINI}_SECRET_KEY
    - LANGFUSE_{AZURE/GEMINI}_PUBLIC_KEY
    - SERVICE1_PROVIDER (azure or gemini)
    - OPENAI_API_KEY
    - OPENROUTER_API_KEY
    - GOOGLE_API_KEY
    - GOOGLE_PROJECT_ID
    - GOOGLE_PRIVATE_KEY
    - GOOGLE_CLIENT_EMAIL
    - GOOGLE_BUCKET_NAME

https://www.perplexity.ai/search/how-to-deploy-a-chainlit-app-o-1_qhFwFxTsO0VFOksS67.Q

https://www.perplexity.ai/search/make-a-minimal-viable-example-zL9hudIbRZCFEjMqaJhiww

### Repo and database ownership

- dataforgoodfr/13_stop_cyberviolence
- kantundpeterpan/chainlit
- chainlit datalayer Postgres DB: kantundpeterpan, currently on neon

### Azure Pipelines / Container Apps, Services

exact Azure Service to be used TBD

https://www.perplexity.ai/search/what-would-be-de-equivalent-of-IBve3EyyTs.n5K_BY65.xw

- Azure Pipelines is granted access to the repo
- cannot build at the moment due to quota issues
