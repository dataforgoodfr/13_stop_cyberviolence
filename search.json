[
  {
    "objectID": "deployment.html",
    "href": "deployment.html",
    "title": "Deployment",
    "section": "",
    "text": "Last updated: 2025-07-21",
    "crumbs": [
      "Documentation",
      "Deployment"
    ]
  },
  {
    "objectID": "deployment.html#docker-files",
    "href": "deployment.html#docker-files",
    "title": "Deployment",
    "section": "Docker files",
    "text": "Docker files\n\n./python_uv_node.Dockerfile\nCustomisation of the UI required forking chainlit, this container contains the base environment for building directly from the fork repo ((p)npm)\n./chainlit_dev.Dockerfile\nBased on the python_uv_node image, for an environment container based on ../chatbot_reqs.txt, requirements possibly a bit bloated\n./chatbot_deploy.Dockerfile\nApp container image, based on the environment image",
    "crumbs": [
      "Documentation",
      "Deployment"
    ]
  },
  {
    "objectID": "deployment.html#local-deployment",
    "href": "deployment.html#local-deployment",
    "title": "Deployment",
    "section": "Local deployment",
    "text": "Local deployment\n\nfrom within the cloned repo, the app can be started using ../docker_call, if the necessary environment variables are set correctly.",
    "crumbs": [
      "Documentation",
      "Deployment"
    ]
  },
  {
    "objectID": "deployment.html#cicd",
    "href": "deployment.html#cicd",
    "title": "Deployment",
    "section": "CI/CD",
    "text": "CI/CD\n\nFrontend changes pushed to production\nThe frontend repo is configured to trigger a rebuild and push to dockerhub of the custom chainlit environment container.\nImportant files, repos\n\ngithub workflow emitting a repository_dispatch on chainlit fork:\n\nproduction branch monstermessenger\n\ngithub workflow processing the repository_dispatch on chatbot repo:\n\nbuild and push the environment container\ntrigger Google Cloud Build/Run to rebuild with the new env-container\n\n\n\n\nBackend / Chainlit python layer changes pushed to production\nChanges pushed to main of the chatbot repo trigger Google Cloud Build/Run (see below)\n\n\nGoogle Cloud Build / Run\n\nGoogle Cloud Build is configured in the github applications of the repo and builds ../chatbot_deploy.Dockerfile on each push to main\nCurrently a single version is running, using the generativelanguage API of Google Cloud\nModel: gemini-flash-2.0\nThe following secrets are set as environment variables in the Google Cloud Run configuration:\n\nLANGFUSE_{AZURE/GEMINI}_SECRET_KEY\nLANGFUSE_{AZURE/GEMINI}_PUBLIC_KEY\nSERVICE1_PROVIDER (azure or gemini)\nOPENAI_API_KEY\nOPENROUTER_API_KEY\nGOOGLE_API_KEY\nGOOGLE_PROJECT_ID\nGOOGLE_PRIVATE_KEY\nGOOGLE_CLIENT_EMAIL\nGOOGLE_BUCKET_NAME\n\n\nhttps://www.perplexity.ai/search/how-to-deploy-a-chainlit-app-o-1_qhFwFxTsO0VFOksS67.Q\nhttps://www.perplexity.ai/search/make-a-minimal-viable-example-zL9hudIbRZCFEjMqaJhiww\n\n\nRepo and database ownership\n\ndataforgoodfr/13_stop_cyberviolence\nkantundpeterpan/chainlit\nchainlit datalayer Postgres DB: kantundpeterpan, currently on neon\n\n\n\nAzure Pipelines / Container Apps, Services\nexact Azure Service to be used TBD, on halt, all cloud resources are on Google Cloud at the moment\nhttps://www.perplexity.ai/search/what-would-be-de-equivalent-of-IBve3EyyTs.n5K_BY65.xw\n\nAzure Pipelines is granted access to the repo\ncannot build at the moment due to quota issues",
    "crumbs": [
      "Documentation",
      "Deployment"
    ]
  },
  {
    "objectID": "local_dev.html",
    "href": "local_dev.html",
    "title": "Local development",
    "section": "",
    "text": "Last updated: 2025-07-21",
    "crumbs": [
      "Documentation",
      "Local development"
    ]
  },
  {
    "objectID": "local_dev.html#chainlit-react-layer",
    "href": "local_dev.html#chainlit-react-layer",
    "title": "Local development",
    "section": "Chainlit React Layer",
    "text": "Chainlit React Layer\n\nPreparation\nIf the frontend environment is ready, proceed as detailed below, else see Section 1.\nclone chainlit fork\ngit clone --single-branch --branch dev_monster https://github.com/kantundpeterpan/chainlit.git\nIn order to launch a REACT development server and connecting the chatbot app, the backend environment needs to be created and the chatbot app repo needs to be cloned see Section 1 and Section 2.\n\n\nFrontend development setup\n\nLaunch React dev server\n\n# from the chainlit repo\ncd frontend/\nnpm run dev\n\n### Output:\nVITE v5.4.14  ready in 1481 ms\n\n  ➜  Local:   http://localhost:5173/\n  ➜  Network: use --host to expose\n  ➜  press h + enter to show help\n###\n\nLaunch chainlit app\n\n# from app repo ./chatbot\nSERVICE1_PROVIDER=gemini chainlit run -h chainlit_app.py\nMake sure all necessary env vars are set correctly (see below).\n\n(Optional if remote) Forward ports\n\nssh user@ip_to_remote -NL 5173:localhost:5173\nssh user@ip_to_remote -NL 8000:localhost:8000\n\nDevelop",
    "crumbs": [
      "Documentation",
      "Local development"
    ]
  },
  {
    "objectID": "local_dev.html#chainlit-python-layer",
    "href": "local_dev.html#chainlit-python-layer",
    "title": "Local development",
    "section": "Chainlit Python layer",
    "text": "Chainlit Python layer\n\nconfig.toml\npublic",
    "crumbs": [
      "Documentation",
      "Local development"
    ]
  },
  {
    "objectID": "datalayer.html",
    "href": "datalayer.html",
    "title": "Chainlit data layer and LLM Observability",
    "section": "",
    "text": "Last updated: 2025-07-21\n\nChainlit data layer\nsee also docs on CL data layer\nThe chainlit app data layer uses the SQLAlchemyDataLayer and the GCSStorageClient implemented in chainlit. This layer captures all user interactions, text is stored in a SQL database (see schema below), and artifacts (images, audio, etc.). The original schema presented at https://docs.chainlit.io/data-layers/sqlalchemy as has been extended by the longfeedbacks table to save input from the custom feedback form.\nThe connection uri for the PostgreSQL is read from the environment variable DL_CONNINFO on runtime. (see also Cloud Configuration)\n--: code-fold: true\nCREATE TABLE users (\n    \"id\" UUID PRIMARY KEY,\n    \"identifier\" TEXT NOT NULL UNIQUE,\n    \"metadata\" JSONB NOT NULL,\n    \"createdAt\" TEXT\n);\n\nCREATE TABLE IF NOT EXISTS threads (\n    \"id\" UUID PRIMARY KEY,\n    \"createdAt\" TEXT,\n    \"name\" TEXT,\n    \"userId\" UUID,\n    \"userIdentifier\" TEXT,\n    \"tags\" TEXT[],\n    \"metadata\" JSONB,\n    FOREIGN KEY (\"userId\") REFERENCES users(\"id\") ON DELETE CASCADE\n);\n\nCREATE TABLE IF NOT EXISTS steps (\n    \"id\" UUID PRIMARY KEY,\n    \"name\" TEXT NOT NULL,\n    \"type\" TEXT NOT NULL,\n    \"threadId\" UUID NOT NULL,\n    \"parentId\" UUID,\n    \"streaming\" BOOLEAN NOT NULL,\n    \"waitForAnswer\" BOOLEAN,\n    \"isError\" BOOLEAN,\n    \"metadata\" JSONB,\n    \"tags\" TEXT[],\n    \"input\" TEXT,\n    \"output\" TEXT,\n    \"createdAt\" TEXT,\n    \"command\" TEXT,\n    \"start\" TEXT,\n    \"end\" TEXT,\n    \"generation\" JSONB,\n    \"showInput\" TEXT,\n    \"language\" TEXT,\n    \"indent\" INT,\n    \"defaultOpen\" BOOLEAN,\n    FOREIGN KEY (\"threadId\") REFERENCES threads(\"id\") ON DELETE CASCADE\n);\n\nCREATE TABLE IF NOT EXISTS elements (\n    \"id\" UUID PRIMARY KEY,\n    \"threadId\" UUID,\n    \"type\" TEXT,\n    \"url\" TEXT,\n    \"chainlitKey\" TEXT,\n    \"name\" TEXT NOT NULL,\n    \"display\" TEXT,\n    \"objectKey\" TEXT,\n    \"size\" TEXT,\n    \"page\" INT,\n    \"language\" TEXT,\n    \"forId\" UUID,\n    \"mime\" TEXT,\n    \"props\" JSONB,\n    FOREIGN KEY (\"threadId\") REFERENCES threads(\"id\") ON DELETE CASCADE\n);\n\nCREATE TABLE IF NOT EXISTS feedbacks (\n    \"id\" UUID PRIMARY KEY,\n    \"forId\" UUID NOT NULL,\n    \"threadId\" UUID NOT NULL,\n    \"value\" INT NOT NULL,\n    \"comment\" TEXT,\n    FOREIGN KEY (\"threadId\") REFERENCES threads(\"id\") ON DELETE CASCADE\n);\n\nCREATE TABLE IF NOT EXISTS longfeedbacks (\n    \"id\" UUID PRIMARY KEY,\n    \"threadId\" UUID UNIQUE NOT NULL,\n    \"value\" INT NOT NULL,\n    \"comment\" TEXT,\n    FOREIGN KEY (\"threadId\") REFERENCES threads(\"id\") ON DELETE CASCADE\n);\n\n\nLLM Observability\nLLM debugging and observability is assured using Langfuse which provides prebuilt callback object for langgraph. Datalayer and LLM traces are linked via the langfuse_session field of the metadata dictionary in the steps table of the PostgreSQL data layer.",
    "crumbs": [
      "Documentation",
      "App data layer and LLM observability"
    ]
  },
  {
    "objectID": "extend_doc.html",
    "href": "extend_doc.html",
    "title": "Extending the documentation",
    "section": "",
    "text": "Last updated: 2025-07-21\n\nPrerequisites\nThe documention used quarto and .qmd quarto markdown (a superset of markdown).\nsee documentation\n\n\nConfiguration\nThe configuration for the static documentation site is defined in chatbot/doc/_quarto.yaml.\n\n\nCreating or modifying parts of the documentation\nAll documents are stored in .qmd format in chatbot/doc. Creation or modification of the documentation does not require local installation of quarto.\nOnce finished, directly push (if you can ;)) or open a pull request to the bot_quarto_docs branch. This will trigger the github workflow defined in build_quarto_docs.yaml.",
    "crumbs": [
      "Documentation",
      "Extending the documentation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stop Cyberviolence",
    "section": "",
    "text": "Last updated: 2025-07-21\nThis page contains an introduction and the technical documentation for the project Stop Cyberviolence as a part of season 13 hosted by Data for Good France.",
    "crumbs": [
      "Project & Team"
    ]
  },
  {
    "objectID": "agent.html",
    "href": "agent.html",
    "title": "Agentic framework and structure",
    "section": "",
    "text": "Last updated: 2025-07-21",
    "crumbs": [
      "Documentation",
      "Agentic framework and structure"
    ]
  },
  {
    "objectID": "agent.html#node-descriptions",
    "href": "agent.html#node-descriptions",
    "title": "Agentic framework and structure",
    "section": "Node descriptions",
    "text": "Node descriptions\n\nagent1\nRouter node that determines the next action based on the message history\ncollect_context\nThis node is only active in the beginning of the conversation and the graph flow is forced through this node until all required context questions have been asked.\nask_for_context\nThe conversation is routed through this node when agent1 determines that the context of the situation still needs clarification.\ngive_advice\nNode responsible for redacting an advice message, is encouraged to invoke research_strategies to enrich answers with ingested documents (see below)\nresearch_strategies\nIs invoked by give_advice, documents provided by the School of Social networks and StopCyberviolence are provided using prompt stuffing. Exchanges between give_advice and research_strategies are handled via the graph state but kept apart from the general message flow in order to save tokens and preserve context.\nescalate\nInvoked when agent1 determines that the situation needs human intervention, logic not yet implemented\nclassify_message\nThis node is an artifact from early development. Its purpose was to provide a tool for the agent to classify the message of interest as cyberviolence using a classical NLP approach. Not implemented (yet), might be removed in the future.\nuser_feedback\nAlso an artifact from early development for debugging purposes, to be removed in the future",
    "crumbs": [
      "Documentation",
      "Agentic framework and structure"
    ]
  },
  {
    "objectID": "agent.html#routings",
    "href": "agent.html#routings",
    "title": "Agentic framework and structure",
    "section": "Routings",
    "text": "Routings\nRouting are either deterministic or conditional on the action chosen by the agent. action is tracked in the current graph state. Conditional routings are not mentioned by name in Figure 1 but indicated by dashed lines between nodes.\n\nrouter\nRouting within the agent’s actions as determined by agent1\ngive_advice_after_context_collection\nArtifact from an attempt to short circuit to give_advice after the initial context collecition is complete, error prone for problematic messages, routes to agent1 in current state\nshould_collect_context\nChecks whether the initial context collection phase has been completed, if not loops to collect_context until done\nadvice_router\nRouting after give_advice, can invoke research_strategies",
    "crumbs": [
      "Documentation",
      "Agentic framework and structure"
    ]
  },
  {
    "objectID": "custom_feedback.html",
    "href": "custom_feedback.html",
    "title": "Custom feedback",
    "section": "",
    "text": "Last updated: 2025-07-21",
    "crumbs": [
      "Documentation",
      "Custom Feedback element"
    ]
  },
  {
    "objectID": "cloud_configuration.html",
    "href": "cloud_configuration.html",
    "title": "Cloud configuration and architecture",
    "section": "",
    "text": "Last updated: 2025-07-21\n\nSecret manager\nAll necessary keys and environment variables are stored in the Google Cloud secret manager. For access contact Valentin, Heiner or Daniel.\n\n\nApp deployment\nThe Google Cloud Build/Run is configured with the repository. For the time being it resources are scaled down to zero depending on demand. This induces a startup delay, when the app is requested after a longer pause.\n\n\nNetwork\nIn order to enable secure communication with the PostgresSQL database of the data layer (which in the future will be hosted on OVH by Centres Relier), the Cloud Run instance is connected to a VPC through which all traffic is routed. The VPC is configured with a static IP address that is authorised for database access.\n\n\nDatalayer\nFor proof-of-concept the app was connected to a serverless PostgresSQL database on neon. This configuration is currently intact but will be subject to change.\n\n\n\n\n\narchitecture-beta\n\n  group github(internet)[GitHub]\n    service repo(server)[Github repo] in github\n\n  group gcp(cloud)[Google Cloud Platform]\n    service build_run(server)[Cloud Build] in gcp\n    service secret_manager(disk)[Secret Manager] in gcp\n    service vpc(internet)[VPC] in gcp\n    service cloud_run(server)[Cloud Run Instance] in gcp\n\n group external(cloud)[External Services]\n    service ovh_postgres(database)[PostgresSQL DB] in external\n    service neon_postgres(database)[Neon Serverless PostgresSQL Database] in external\n\n  %% Define the relationships\n    repo:T -- B:build_run\n    secret_manager:L -- R:cloud_run\n    build_run:T -- B:cloud_run\n    cloud_run:T -- B:vpc\n    vpc:T -- B:ovh_postgres\n    vpc:T -- B:neon_postgres",
    "crumbs": [
      "Documentation",
      "Cloud configuration"
    ]
  }
]