[
  {
    "objectID": "deployment.html",
    "href": "deployment.html",
    "title": "Deployment",
    "section": "",
    "text": "Last updated: 2025-06-05\n\n\n\n./python_uv_node.Dockerfile\nCustomisation of the UI required forking chainlit, this container contains the base environment for building directly from the fork repo ((p)npm)\n./chainlit_dev.Dockerfile\nBased on the python_uv_node image, for an environment container based on ../chatbot_reqs.txt, requirements possibly a bit bloated\n./chatbot_deploy.Dockerfile\nApp container image, based on the environment image\n\n\n\n\n\nfrom within the cloned repo, the app can be started using ../docker_call, if the necessary environment variables are set correctly.\n\n\n\n\n\n\nThe frontend repo is configured to trigger a rebuild and push to dockerhub of the custom chainlit environment container.\nImportant files, repos\n\ngithub workflow emitting a repository_dispatch on chainlit fork:\n\nproduction branch monstermessenger\n\ngithub workflow processing the repository_dispatch on chatbot repo:\n\nbuild and push the environment container\ntrigger Google Cloud Build/Run to rebuild with the new env-container\n\n\n\n\n\nChanges pushed to main of the chatbot repo trigger Google Cloud Build/Run (see below)\n\n\n\n\nGoogle Cloud Build is configured in the github applications of the repo and builds ..//chatbot_deploy.Dockerfile on each push to main\nCurrently a single version is running, using the generativelanguage API of Google Cloud\nModel: gemini-flash-2.0\nThe following secrets are set as environment variables in the Google Cloud Run configuration:\n\nLANGFUSE_{AZURE/GEMINI}_SECRET_KEY\nLANGFUSE_{AZURE/GEMINI}_PUBLIC_KEY\nSERVICE1_PROVIDER (azure or gemini)\nOPENAI_API_KEY\nOPENROUTER_API_KEY\nGOOGLE_API_KEY\nGOOGLE_PROJECT_ID\nGOOGLE_PRIVATE_KEY\nGOOGLE_CLIENT_EMAIL\nGOOGLE_BUCKET_NAME\n\n\nhttps://www.perplexity.ai/search/how-to-deploy-a-chainlit-app-o-1_qhFwFxTsO0VFOksS67.Q\nhttps://www.perplexity.ai/search/make-a-minimal-viable-example-zL9hudIbRZCFEjMqaJhiww\n\n\n\n\ndataforgoodfr/13_stop_cyberviolence\nkantundpeterpan/chainlit\nchainlit datalayer Postgres DB: kantundpeterpan, currently on neon\n\n\n\n\nexact Azure Service to be used TBD\nhttps://www.perplexity.ai/search/what-would-be-de-equivalent-of-IBve3EyyTs.n5K_BY65.xw\n\nAzure Pipelines is granted access to the repo\ncannot build at the moment due to quota issues",
    "crumbs": [
      "Documentation",
      "Deployment"
    ]
  },
  {
    "objectID": "deployment.html#docker-files",
    "href": "deployment.html#docker-files",
    "title": "Deployment",
    "section": "",
    "text": "./python_uv_node.Dockerfile\nCustomisation of the UI required forking chainlit, this container contains the base environment for building directly from the fork repo ((p)npm)\n./chainlit_dev.Dockerfile\nBased on the python_uv_node image, for an environment container based on ../chatbot_reqs.txt, requirements possibly a bit bloated\n./chatbot_deploy.Dockerfile\nApp container image, based on the environment image",
    "crumbs": [
      "Documentation",
      "Deployment"
    ]
  },
  {
    "objectID": "deployment.html#local-deployment",
    "href": "deployment.html#local-deployment",
    "title": "Deployment",
    "section": "",
    "text": "from within the cloned repo, the app can be started using ../docker_call, if the necessary environment variables are set correctly.",
    "crumbs": [
      "Documentation",
      "Deployment"
    ]
  },
  {
    "objectID": "deployment.html#cicd",
    "href": "deployment.html#cicd",
    "title": "Deployment",
    "section": "",
    "text": "The frontend repo is configured to trigger a rebuild and push to dockerhub of the custom chainlit environment container.\nImportant files, repos\n\ngithub workflow emitting a repository_dispatch on chainlit fork:\n\nproduction branch monstermessenger\n\ngithub workflow processing the repository_dispatch on chatbot repo:\n\nbuild and push the environment container\ntrigger Google Cloud Build/Run to rebuild with the new env-container\n\n\n\n\n\nChanges pushed to main of the chatbot repo trigger Google Cloud Build/Run (see below)\n\n\n\n\nGoogle Cloud Build is configured in the github applications of the repo and builds ..//chatbot_deploy.Dockerfile on each push to main\nCurrently a single version is running, using the generativelanguage API of Google Cloud\nModel: gemini-flash-2.0\nThe following secrets are set as environment variables in the Google Cloud Run configuration:\n\nLANGFUSE_{AZURE/GEMINI}_SECRET_KEY\nLANGFUSE_{AZURE/GEMINI}_PUBLIC_KEY\nSERVICE1_PROVIDER (azure or gemini)\nOPENAI_API_KEY\nOPENROUTER_API_KEY\nGOOGLE_API_KEY\nGOOGLE_PROJECT_ID\nGOOGLE_PRIVATE_KEY\nGOOGLE_CLIENT_EMAIL\nGOOGLE_BUCKET_NAME\n\n\nhttps://www.perplexity.ai/search/how-to-deploy-a-chainlit-app-o-1_qhFwFxTsO0VFOksS67.Q\nhttps://www.perplexity.ai/search/make-a-minimal-viable-example-zL9hudIbRZCFEjMqaJhiww\n\n\n\n\ndataforgoodfr/13_stop_cyberviolence\nkantundpeterpan/chainlit\nchainlit datalayer Postgres DB: kantundpeterpan, currently on neon\n\n\n\n\nexact Azure Service to be used TBD\nhttps://www.perplexity.ai/search/what-would-be-de-equivalent-of-IBve3EyyTs.n5K_BY65.xw\n\nAzure Pipelines is granted access to the repo\ncannot build at the moment due to quota issues",
    "crumbs": [
      "Documentation",
      "Deployment"
    ]
  },
  {
    "objectID": "agent.html",
    "href": "agent.html",
    "title": "Agentic framework and structure",
    "section": "",
    "text": "stateDiagram-v2\n  u: User input\n  a1: Agent service 1\n  r1: Research assistant\n  class1: classifier\n\n\n  u --&gt; a1\n  a1 --&gt; u : context questions\n  a2 --&gt; u : interaction\n\n  a1 --&gt; a2 : handoff\nService1 --&gt; Service2 : Cyberviolence detection\n\nstate Service1 {\n  a1 --&gt; r1\n  r1 --&gt; a1\n  a1 --&gt; class1\n  class1 --&gt; a1\n}\n\n\nstate Service2{\n  a2: Agent service 2\n  r2: Research assistant\n\n  a2 --&gt; r2\n  r2 --&gt; a2\n}\n\n\nService2 --&gt; Service3 : referral to specialized service necessary\n\na2 --&gt; a3 : handoff\na3 --&gt; u : interaction\n\nstate Service3 {\n  a3: Agent Service 3\n  r3: Research assistant 3\n\n  a3 --&gt; r3\n  r3 --&gt; a3\n}\n\nend : End\n\nService3 --&gt; end",
    "crumbs": [
      "Documentation",
      "Agentic framework and structure"
    ]
  },
  {
    "objectID": "agent.html#prospective-design",
    "href": "agent.html#prospective-design",
    "title": "Agentic framework and structure",
    "section": "",
    "text": "stateDiagram-v2\n  u: User input\n  a1: Agent service 1\n  r1: Research assistant\n  class1: classifier\n\n\n  u --&gt; a1\n  a1 --&gt; u : context questions\n  a2 --&gt; u : interaction\n\n  a1 --&gt; a2 : handoff\nService1 --&gt; Service2 : Cyberviolence detection\n\nstate Service1 {\n  a1 --&gt; r1\n  r1 --&gt; a1\n  a1 --&gt; class1\n  class1 --&gt; a1\n}\n\n\nstate Service2{\n  a2: Agent service 2\n  r2: Research assistant\n\n  a2 --&gt; r2\n  r2 --&gt; a2\n}\n\n\nService2 --&gt; Service3 : referral to specialized service necessary\n\na2 --&gt; a3 : handoff\na3 --&gt; u : interaction\n\nstate Service3 {\n  a3: Agent Service 3\n  r3: Research assistant 3\n\n  a3 --&gt; r3\n  r3 --&gt; a3\n}\n\nend : End\n\nService3 --&gt; end",
    "crumbs": [
      "Documentation",
      "Agentic framework and structure"
    ]
  },
  {
    "objectID": "agent.html#implementation",
    "href": "agent.html#implementation",
    "title": "Agentic framework and structure",
    "section": "Implementation",
    "text": "Implementation\nJ’ai choisi langgraph en combinaison avec langchain. Les deux sont open-source, avec une documentation extensive et de nombreux tutoriels disponibles.\nPour un premier draft, je me suis inspiré (entre autres) de cet article.\nPour le premier draft, nous nous concentrons sur le service 1 “Aide à la réponse”.\nLe modèle utilisé est GPT-4o-mini de OpenAIsans raison spécifique. Gemini 2.0 Flash pour sa fenêtre de contexte très large. Avec GPT-4o-mini, on arrivait déjà à la limite ce qui reste suspicieux (code à vérifier). Les calls de API passe maintenant par OpenRouter, cela permet de facilement changer les modèles pour un prototypage rapide. Potentiellement, on pourra envisager d’utiliser différents modèles pour différents tâches.\nÉtat actuel\n\nLe routage fonctionne (par exemple, “je me sens en danger” active la voie ‘escalate’), à vérifier en language ados.\nPour l’instant, j’ai l’impression que nous devons forcer l’agent à solliciter le RESEARCHER ou le CLASSIFIER (du genre à demander directement).\nChaque node a un prompt qui reste à definir/améliorer.\nTODO\n\nAgent\n\nLe début de l’échange doit être amélioré (le bot doit se présenter et préparer le terrain).\nagent1 doit probablement etre converti en simple point de routage\ndefinition des informations contextuelle minimales\n\n\n\nSituational context\nPour bien comprendre la situation qui a conduit le jeune / ado à soliciter le chatbot, on a besoin des infos suivants:\n\nRôle du jeune: Expéditeur (potentitiel), destinataire ou témoin\nLe canal de communication par lequel le message est arrivé chez le jeune\nLe ressenti que le message a évoqué\n\nImplementation\nDeux solutions semblent envisageables:\n\nSéries des questions déterminstes au début de l’échange, les infos sont enregistré dans dictionnaire\nDéfintion d’un dictionnaire avec des champs prédefinis, la collecte des informations est laissé au LLM\n\nDans les deux cas, les informations devront être injectés dans les system prompts.\n\n\nRAG pour research_strategies\nOn part pour une exploration de kotaemon, un open-source RAG tool. Ce qui sera probablement le plus intéressant, sont les procédures de traitement des documents, les embeddings, le stockage et le retrieval.\nEst-ce qu’on ne garderait pqs l’UI kotaemon pour la gestion des documents ?\n\nListe des documents à ingérer\nQuel vectorstore ?\nProcédure de retrieval des informations.\n\n\n\nNLP message classifier (priorite moindre)\n\nModèle de classification du dataset cyberagressionado-v1.\nProcédure pour que CLASSIFIER1 puisse se servir du modèle de classification (peut-être ce sera plutôt un outil pour AGENT1 qu’un agent spécialisé).\n\n\n\nInterface graphique\n\nInterface graphique de base en place, implementé avec chainlit\nsupport envoi capture d’ecran\nCustomisation ….\n\n\n\nExemple d’un échange\n\nEnter your query (type '-q' to quit):\n&gt; ================================== Ai Message ==================================\n\nI understand that you're feeling upset about what happened. It's really important to talk about it. Can you tell me more about what was said or done? This will help me understand the situation better.\n\n---\n Routed to:  USER\n---\n\n&gt; : ================================ Human Message =================================\n\nhi, est-ce qu'on peut discuter en francais ?\n\n================================== Ai Message ==================================\n\nBien sûr, nous pouvons discuter en français ! Je suis là pour t'aider. Peux-tu me dire ce qui te préoccupe ?\n\n---\n Routed to:  USER\n---\n\n&gt; : ================================ Human Message =================================\n\nj'ai recu un message de qqn que je connais pas vraiment. je comprends pas trop ce que ca veut dire\n\n================================== Ai Message ==================================\n\nJe comprends que recevoir un message d'une personne que tu ne connais pas peut être déroutant et même un peu inquiétant. Peux-tu me dire ce que le message disait ? Cela m'aidera à mieux comprendre la situation et à te donner des conseils appropriés.\n\n---\n Routed to:  USER\n---\n\n&gt; : ================================ Human Message =================================\n\nil m'a dit que je suis moche\n\n================================== Ai Message ==================================\n\nJe suis vraiment désolé d'apprendre que tu as reçu un message aussi blessant. C'est très injuste et tu ne mérites pas d'être traité de cette façon. Les commentaires comme celui-ci sont une forme de cyberharcèlement, et c'est important de se rappeler que ce n'est pas de ta faute.\n\nVoici quelques étapes que tu peux suivre :\n1. **Ne réponds pas** à ce message. Parfois, ignorer les personnes qui essaient de te blesser est la meilleure chose à faire.\n2. **Prends une capture d'écran** du message pour garder une preuve de ce qui a été dit.\n3. **Bloque la personne** sur la plateforme où tu as reçu le message. Cela peut t'aider à te sentir plus en sécurité.\n4. **Parle-en à un adulte de confiance**, comme un parent, un enseignant ou un conseiller scolaire. Ils peuvent t'aider à gérer la situation.\n\nN'oublie pas que tu n'es pas seul et qu'il y a des gens qui se soucient de toi et qui peuvent t'aider. Tu es précieux et tu mérites d'être traité avec respect !\n\n---\n Routed to:  USER\n---\n\n&gt; : ================================ Human Message =================================\n\ntu me conseilles de faire quoi?\n\n================================== Ai Message ==================================\n\nJe te conseille de suivre ces étapes :\n\n1. **Ne réponds pas** au message. Ignorer les personnes qui essaient de te blesser est souvent la meilleure option.\n2. **Prends une capture d'écran** du message pour garder une preuve de ce qui a été dit. Cela peut être utile si tu en parles à un adulte.\n3. **Bloque la personne** sur la plateforme où tu as reçu le message. Cela peut t'aider à te sentir plus en sécurité et à éviter d'autres messages blessants.\n4. **Parle-en à un adulte de confiance**, comme un parent, un enseignant ou un conseiller scolaire. Ils peuvent t'aider à gérer la situation et à te soutenir.\n\nN'oublie pas que tu n'es pas seul et qu'il y a des gens qui se soucient de toi et qui peuvent t'aider. Tu es précieux et tu mérites d'être traité avec respect !\n\n---\n Routed to:  USER\n---\n\n&gt; : ================================ Human Message =================================\n\ntu crois que c'est du cyberharcelement?\n\n================================== Ai Message ==================================\n\nOui, ce que tu as décrit ressemble à du cyberharcèlement. Quand quelqu'un t'envoie des messages blessants ou méchants, cela fait partie des comportements de harcèlement en ligne. C'est important de se rappeler que ce n'est pas de ta faute et que tu ne mérites pas d'être traité de cette manière.\n\nSi tu veux, je peux t'aider à prendre des mesures pour te protéger et te sentir mieux. Que souhaites-tu faire ?\n\n---\n Routed to:  CLASSIFIER1\n---\n\n================================== Ai Message ==================================\n\nClearly cyberviolence\n\n================================== Ai Message ==================================\n\nJe pense qu'il est important de prendre cette situation au sérieux. Étant donné que tu as reçu un message blessant et que cela ressemble à du cyberharcèlement, je vais transférer ton cas à un service spécialisé qui pourra t'aider davantage. Ils pourront te fournir le soutien dont tu as besoin.\n\nN'oublie pas que tu n'es pas seul et qu'il y a des gens qui se soucient de toi. Je vais maintenant te transférer à ce service.\n\n---\n Routed to:  SERVICE2\n---\n\n================================== Ai Message ==================================\n\nService 2 not yet implemented",
    "crumbs": [
      "Documentation",
      "Agentic framework and structure"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stop Cyberviolence",
    "section": "",
    "text": "This page contains an introduction and the technical documentation for the project Stop Cyberviolence as a part of season 13 hosted by Data for Good France.",
    "crumbs": [
      "Project & Team"
    ]
  },
  {
    "objectID": "extend_doc.html",
    "href": "extend_doc.html",
    "title": "Extending the documentation",
    "section": "",
    "text": "Prerequisites\nThe documention used quarto and .qmd quarto markdown (a superset of markdown).\nsee documentation\n\n\nConfiguration\nThe configuration for the static documentation site is defined in chatbot/doc/_quarto.yaml.\n\n\nCreating or modifying parts of the documentation\nAll documents are stored in .qmd format in chatbot/doc. Creation or modification of the documentation does not require local installation of quarto.\nOnce finished, directly push (if you can ;)) or open a pull request to the bot_quarto_docs branch. This will trigger the github workflow defined in build_quarto_docs.yaml.",
    "crumbs": [
      "Documentation",
      "Extending the documentation"
    ]
  },
  {
    "objectID": "local_dev.html",
    "href": "local_dev.html",
    "title": "Local development",
    "section": "",
    "text": "The project uses a combination of mamba (conda) (non-python dependencies) and uv (python dependecies) for environment management.\nBackend environment\nmamba create -n stopcyber_backend -c conda-forge uv \nuv pip install -r ./chatbot/chatbot_reqs.txt\nFrontend environment\nmamba create -n stopcyber_frontend -c conda-forge nodejs pnpm",
    "crumbs": [
      "Documentation",
      "Local development"
    ]
  },
  {
    "objectID": "local_dev.html#chainlit-react-layer",
    "href": "local_dev.html#chainlit-react-layer",
    "title": "Local development",
    "section": "Chainlit React Layer",
    "text": "Chainlit React Layer\n\nPreparation\nIf the frontend environment is ready, proceed as detailed below, else see Section 1.\nclone chainlit fork\ngit clone --single-branch --branch dev_monster https://github.com/kantundpeterpan/chainlit.git\nIn order to launch a REACT development server and connecting the chatbot app, the backend environment needs to be created and the chatbot app repo needs to be cloned see Section 1 and Section 2.\n\n\nFrontend development setup\n\nLaunch React dev server\n\n# from the chainlit repo\ncd frontend/\nnpm run dev\n\n### Output:\nVITE v5.4.14  ready in 1481 ms\n\n  ➜  Local:   http://localhost:5173/\n  ➜  Network: use --host to expose\n  ➜  press h + enter to show help\n###\n\nLaunch chainlit app\n\n# from app repo ./chatbot\nSERVICE1_PROVIDER=gemini chainlit run -h chainlit_app.py\nMake sure all necessary env vars are set correctly (see below).\n\n(Optional if remote) Forward ports\n\nssh ip_to_remote -NL 5173:localhost:5173\nssh ip_to_remote -NL 8000:localhost:8000\n\nDevelop",
    "crumbs": [
      "Documentation",
      "Local development"
    ]
  },
  {
    "objectID": "local_dev.html#chainlit-python-layer",
    "href": "local_dev.html#chainlit-python-layer",
    "title": "Local development",
    "section": "Chainlit Python layer",
    "text": "Chainlit Python layer\n\nconfig.toml\npublic",
    "crumbs": [
      "Documentation",
      "Local development"
    ]
  }
]